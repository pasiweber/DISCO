{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:10:30.588168Z",
     "start_time": "2024-07-03T14:10:29.446448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%store -r DISCO_ROOT_FOLDER\n",
    "if \"DISCO_ROOT_FOLDER\" in globals():\n",
    "    os.chdir(DISCO_ROOT_FOLDER)\n",
    "    sys.path.append(DISCO_ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.real_world_datasets import Datasets as RealWorldDatasets\n",
    "from datasets.density_datasets import Datasets as DensityDatasets\n",
    "# from src.utils.metrics import METRICS, SELECTED_METRICS\n",
    "from src.utils.metrics import METRIC_ABBREV_PLAIN\n",
    "\n",
    "METRICS = [\n",
    "    \"DISCO\",\n",
    "    # \"DC_DUNN\",\n",
    "    ### Competitors\n",
    "    \"DBCV\",\n",
    "    # \"DBCV_eucl\",\n",
    "    \"DCSI\",\n",
    "    \"LCCV\",\n",
    "    \"VIASCKDE\",\n",
    "    \"CVDD\",\n",
    "    \"CDBW\",\n",
    "    \"CVNN\",\n",
    "    # \"DSI\",\n",
    "    ### Gauss\n",
    "    \"SILHOUETTE\",\n",
    "    \"S_DBW\",\n",
    "    # \"DUNN\",\n",
    "    # \"DB\",\n",
    "    # \"CH\",\n",
    "]\n",
    "\n",
    "RUNTIME_METRICS = METRICS.copy()\n",
    "RUNTIME_METRICS.remove(\"CVDD\")\n",
    "\n",
    "configs = {\n",
    "    # Real World Datasets\n",
    "    \"real_world_colored_column_wise\": {\n",
    "        \"paths\": [\"results/real_world/\"],\n",
    "        \"latex_path\": \"latex/real_world_experiments.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on real-world datasets. Column-wise Green.\",\n",
    "        \"categories\": [\n",
    "            (\"Synth_low\", 8, \"Tabular data\"),\n",
    "            (\"Weizmann\", 2, \"Video\"),\n",
    "            (\"COIL20\", 3, \"Image\"),\n",
    "            (\"Optdigits\", 5, \"MNIST\"),\n",
    "        ],\n",
    "        \"latex_coloring_axis\": 0,\n",
    "        \"latex_coloring_selection\": None,\n",
    "    },\n",
    "    \"real_world_standardized_colored_column_wise\": {\n",
    "        \"paths\": [\"results/real_world_standardized/\"],\n",
    "        \"latex_path\": \"latex/real_world_experiments_standardized.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on real-world datasets (standardized). Column-wise Green.\",\n",
    "        \"categories\": [\n",
    "            (\"Synth_low\", 8, \"Tabular data\"),\n",
    "            (\"Weizmann\", 2, \"Video\"),\n",
    "            (\"COIL20\", 3, \"Image\"),\n",
    "            (\"Optdigits\", 5, \"MNIST\"),\n",
    "        ],\n",
    "        \"latex_coloring_axis\": 0,\n",
    "        \"latex_coloring_selection\": None,\n",
    "    },\n",
    "    # \"real_world_colored_row_wise_selected\": {\n",
    "    #     \"paths\": [\"results/real_world/\"],\n",
    "    #     \"latex_path\": \"latex/real_world_experiments (selected).tex\",\n",
    "    #     \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "    #     \"aggregation_funcs\": [\"mean\"],\n",
    "    #     \"metrics\": METRICS,\n",
    "    #     \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "    #     \"selection\": [\"value\"],\n",
    "    #     \"caption\": \"Evaluating on real-world datasets. Row-wise Green of selected ones.\",\n",
    "    #     \"categories\": [\n",
    "    #         (\"Synth_low\", 8, \"Tabular data\"),\n",
    "    #         (\"Weizmann\", 2, \"Video\"),\n",
    "    #         (\"COIL20\", 3, \"Image\"),\n",
    "    #         (\"Optdigits\", 5, \"MNIST\"),\n",
    "    #     ],\n",
    "    #     \"latex_coloring_axis\": 1,\n",
    "    #     \"latex_coloring_selection\": [\"DISCO\", \"DBCV\", \"DCSI\", \"S_DBW\", \"DSI\", \"SILHOUETTE\", \"DUNN\"],\n",
    "    # },\n",
    "    # \"real_world_standardized_colored_row_wise_selected\": {\n",
    "    #     \"paths\": [\"results/real_world_standardized/\"],\n",
    "    #     \"latex_path\": \"latex/real_world_experiments_standardized (selected).tex\",\n",
    "    #     \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "    #     \"aggregation_funcs\": [\"mean\"],\n",
    "    #     \"metrics\": METRICS,\n",
    "    #     \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "    #     \"selection\": [\"value\"],\n",
    "    #     \"caption\": \"Evaluating on real-world datasets (standardized). Row-wise Green of selected ones.\",\n",
    "    #     \"categories\": [\n",
    "    #         (\"Synth_low\", 8, \"Tabular data\"),\n",
    "    #         (\"Weizmann\", 2, \"Video\"),\n",
    "    #         (\"COIL20\", 3, \"Image\"),\n",
    "    #         (\"Optdigits\", 5, \"MNIST\"),\n",
    "    #     ],\n",
    "    #     \"latex_coloring_axis\": 1,\n",
    "    #     \"latex_coloring_selection\": [\"DISCO\", \"DBCV\", \"DCSI\", \"S_DBW\", \"DSI\", \"SILHOUETTE\", \"DUNN\"],\n",
    "    # },\n",
    "    # Density Datasets\n",
    "    \"density_colored_column_wise\": {\n",
    "        \"paths\": [\"results/density/\"],\n",
    "        \"latex_path\": \"latex/density_experiments.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on density datasets. Column-wise Green.\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": 0,\n",
    "        \"latex_coloring_selection\": None,\n",
    "    },\n",
    "    \"density_standardized_colored_column_wise\": {\n",
    "        \"paths\": [\"results/density_standardized/\"],\n",
    "        \"latex_path\": \"latex/density_experiments_standardized.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on density datasets (standardized). Column-wise Green.\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": 0,\n",
    "        \"latex_coloring_selection\": None,\n",
    "    },\n",
    "    # \"density_colored_row_wise_selected\": {\n",
    "    #     \"paths\": [\"results/density/\"],\n",
    "    #     \"latex_path\": \"latex/density_experiments (selected).tex\",\n",
    "    #     \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "    #     \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "    #     \"metrics\": METRICS,\n",
    "    #     \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "    #     \"selection\": [\"value\"],\n",
    "    #     \"caption\": \"Evaluating on density datasets. Row-wise Green of selected ones.\",\n",
    "    #     \"categories\": [],\n",
    "    #     \"latex_coloring_axis\": 1,\n",
    "    #     \"latex_coloring_selection\": [\"DISCO\", \"DBCV\", \"DCSI\", \"S_DBW\", \"DSI\", \"SILHOUETTE\", \"DUNN\"],\n",
    "    # },\n",
    "    # \"density_standardized_colored_row_wise_selected\": {\n",
    "    #     \"paths\": [\"results/density_standardized/\"],\n",
    "    #     \"latex_path\": \"latex/density_experiments_standardized (selected).tex\",\n",
    "    #     \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "    #     \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "    #     \"metrics\": METRICS,\n",
    "    #     \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "    #     \"selection\": [\"value\"],\n",
    "    #     \"caption\": \"Evaluating on density datasets (standardized). Row-wise Green of selected ones.\",\n",
    "    #     \"categories\": [],\n",
    "    #     \"latex_coloring_axis\": 1,\n",
    "    #     \"latex_coloring_selection\": [\"DISCO\", \"DBCV\", \"DCSI\", \"S_DBW\", \"DSI\", \"SILHOUETTE\", \"DUNN\"],\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_runtimes = {\n",
    "    # Runtimes\n",
    "    \"real_world_colored_row_wise_time\": {\n",
    "        \"paths\": [\"results/real_world_standardized/\"],\n",
    "        \"latex_path\": \"latex/real_world_experiments_standardized_time.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"metric_abbrev\": METRIC_ABBREV_PLAIN,\n",
    "        \"lower_is_better\": METRICS,\n",
    "        \"selection\": [\"time\"],\n",
    "        \"caption\": \"Total time runtime on real world datasets. (coloring excluded CVDD)\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": 1,\n",
    "        \"latex_coloring_selection\": RUNTIME_METRICS,\n",
    "    },\n",
    "    \"real_world_colored_row_wise_process_time\": {\n",
    "        \"paths\": [\"results/real_world_standardized/\"],\n",
    "        \"latex_path\": \"latex/real_world_experiments_standardized_process_time.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"metric_abbrev\": METRIC_ABBREV_PLAIN,\n",
    "        \"lower_is_better\": METRICS,\n",
    "        \"selection\": [\"process_time\"],\n",
    "        \"caption\": \"Total process runtime on real world datasets. (coloring excluded CVDD)\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": 1,\n",
    "        \"latex_coloring_selection\": RUNTIME_METRICS,\n",
    "    },\n",
    "    \"density_colored_row_wise_time\": {\n",
    "        \"paths\": [\"results/density_standardized/\"],\n",
    "        \"latex_path\": \"latex/density_experiments_standardized_time.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"metric_abbrev\": METRIC_ABBREV_PLAIN,\n",
    "        \"lower_is_better\": METRICS,\n",
    "        \"selection\": [\"time\"],\n",
    "        \"caption\": \"Total time runtime on density datasets. (coloring excluded CVDD)\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": 1,\n",
    "        \"latex_coloring_selection\": RUNTIME_METRICS,\n",
    "    },\n",
    "    \"density_colored_row_wise_process_time\": {\n",
    "        \"paths\": [\"results/density_standardized/\"],\n",
    "        \"latex_path\": \"latex/density_experiments_standardized_process_time.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\", \"std\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"metric_abbrev\": METRIC_ABBREV_PLAIN,\n",
    "        \"lower_is_better\": METRICS,\n",
    "        \"selection\": [\"process_time\"],\n",
    "        \"caption\": \"Total process runtime on density datasets. (coloring excluded CVDD)\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": 1,\n",
    "        \"latex_coloring_selection\": RUNTIME_METRICS,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.cluster_algorithms import CLUSTER_ALGORITHMS, CLUSTER_ABBREV\n",
    "\n",
    "config_clusterings = {\n",
    "    # Clusterings\n",
    "    \"density_standardized_colored_row_wise_clusterings\": {\n",
    "        \"paths\": [\"clustering_results2/density_standardized/\"],\n",
    "        \"latex_path\": \"latex/density_standardized_clusterings.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": list(CLUSTER_ALGORITHMS.keys()),\n",
    "        \"metric_abbrev\": CLUSTER_ABBREV,\n",
    "        # \"lower_is_better\": METRICS,\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"DISCO values on different Clusterings\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": None,\n",
    "        # \"latex_coloring_selection\": RUNTIME_METRICS,\n",
    "    },\n",
    "    # ARI\n",
    "    \"density_standardized_colored_row_wise_clusterings_ari\": {\n",
    "        \"paths\": [\"results/ari/density_standardized/\"],\n",
    "        \"latex_path\": \"latex/density_standardized_clusterings_ari.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in DensityDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": list(CLUSTER_ALGORITHMS.keys()),\n",
    "        \"metric_abbrev\": CLUSTER_ABBREV,\n",
    "        # \"lower_is_better\": METRICS,\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"ARI values on different Clusterings\",\n",
    "        \"categories\": [],\n",
    "        \"latex_coloring_axis\": None,\n",
    "        # \"latex_coloring_selection\": RUNTIME_METRICS,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    RealWorldDatasets.htru2,\n",
    "    # RealWorldDatasets.Pendigits,\n",
    "    # RealWorldDatasets.Mice,\n",
    "    # RealWorldDatasets.letterrec,\n",
    "    RealWorldDatasets.HAR,\n",
    "    # RealWorldDatasets.cmu_faces,\n",
    "    # RealWorldDatasets.Optdigits,\n",
    "    # RealWorldDatasets.USPS,\n",
    "    RealWorldDatasets.MNIST,\n",
    "    # RealWorldDatasets.KMNIST,\n",
    "    # RealWorldDatasets.FMNIST,\n",
    "    DensityDatasets.smile1,\n",
    "    DensityDatasets.dartboard1,\n",
    "    DensityDatasets.chainlink,\n",
    "    DensityDatasets.three_spiral,\n",
    "    DensityDatasets.complex8,\n",
    "    DensityDatasets.complex9,\n",
    "    DensityDatasets.compound,\n",
    "    DensityDatasets.aggregation,\n",
    "    DensityDatasets.cluto_t8_8k,\n",
    "    DensityDatasets.cluto_t7_10k,\n",
    "    DensityDatasets.cluto_t4_8k,\n",
    "    DensityDatasets.diamond9,\n",
    "    # DensityDatasets.cluto_t5_8k,\n",
    "    RealWorldDatasets.Synth_high,\n",
    "    RealWorldDatasets.Synth_low,\n",
    "    RealWorldDatasets.COIL20,\n",
    "    # RealWorldDatasets.COIL100,\n",
    "    RealWorldDatasets.Weizmann,\n",
    "    RealWorldDatasets.Keck,\n",
    "]\n",
    "\n",
    "dataset_names = [dataset.name for dataset in dataset_names]\n",
    "\n",
    "config_final = {\n",
    "    \"all_experiments_standardized\": {\n",
    "        \"paths\": [\"results/real_world_standardized/\", \"results/density_standardized/\"],\n",
    "        \"latex_path\": \"latex/all_experiments_standardized.tex\",\n",
    "        \"dataset_names\": dataset_names,\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"lower_is_better\": [\"CVNN\", \"DCVI\", \"S_DBW\"],\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on several datasets (standardized). Column-wise Green.\",\n",
    "        # \"categories\": [\n",
    "        #     (\"htru2\", 3, \"Tabular data\"),\n",
    "        #     # (\"cmu_faces\", 6, \"Image data\"),\n",
    "        #     (\"smile1\", 12, \"Tomas Barton Benchmark\"),\n",
    "        #     (\"Synth_high\", 6, \"High-dimensional\"),\n",
    "        # ],\n",
    "        \"latex_coloring_axis\": 0,\n",
    "        \"latex_coloring_selection\": None,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: `latex/density_standardized_clusterings_ari.tex`\n",
      "Generated: `latex/density_standardized_clusterings.tex`\n",
      "Generated: `latex/all_experiments_standardized.tex`\n"
     ]
    }
   ],
   "source": [
    "from src.utils.latex_pandas import generate_latex_file\n",
    "from mpire.pool import WorkerPool\n",
    "\n",
    "pool = WorkerPool(n_jobs=30, use_dill=True)\n",
    "# pool.map_unordered(generate_latex_file, configs.values())\n",
    "# pool.map_unordered(generate_latex_file, config_runtimes.values())\n",
    "pool.map_unordered(generate_latex_file, config_clusterings.values())\n",
    "pool.map_unordered(generate_latex_file, config_final.values())\n",
    "pool.stop_and_join()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: `latex/all_experiments_standardized.tex`\n"
     ]
    }
   ],
   "source": [
    "from src.utils.latex_pandas import generate_latex_file\n",
    "\n",
    "generate_latex_file(**config_final[\"all_experiments_standardized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>DBSCAN</th>\n",
       "      <th>HDBSCAN</th>\n",
       "      <th>DPC</th>\n",
       "      <th>SpectralClustering</th>\n",
       "      <th>Agglomerative</th>\n",
       "      <th>KMeans</th>\n",
       "      <th>Random_k</th>\n",
       "      <th>Random_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3-spiral</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.787216</td>\n",
       "      <td>0.823621</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chainlink</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.201572</td>\n",
       "      <td>0.503609</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.064090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939437</td>\n",
       "      <td>0.870157</td>\n",
       "      <td>0.311191</td>\n",
       "      <td>0.437614</td>\n",
       "      <td>0.511867</td>\n",
       "      <td>0.465176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.248785</td>\n",
       "      <td>0.198642</td>\n",
       "      <td>0.361618</td>\n",
       "      <td>0.327539</td>\n",
       "      <td>0.360767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.610912</td>\n",
       "      <td>0.811086</td>\n",
       "      <td>0.740208</td>\n",
       "      <td>0.561191</td>\n",
       "      <td>0.501062</td>\n",
       "      <td>0.527150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dartboard1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diamond9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875442</td>\n",
       "      <td>0.769478</td>\n",
       "      <td>0.151082</td>\n",
       "      <td>0.964994</td>\n",
       "      <td>0.996266</td>\n",
       "      <td>0.961846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332665</td>\n",
       "      <td>0.636015</td>\n",
       "      <td>0.568858</td>\n",
       "      <td>0.545919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GroundTruth    DBSCAN   HDBSCAN       DPC  SpectralClustering  \\\n",
       "3-spiral             1.0  1.000000  0.942517  1.000000           -0.004251   \n",
       "aggregation          1.0  0.974067  0.808943  0.787216            0.823621   \n",
       "chainlink            1.0  1.000000  1.000000  0.201572            0.503609   \n",
       "complex8             1.0  0.939437  0.870157  0.311191            0.437614   \n",
       "complex9             1.0  0.999518  0.248785  0.198642            0.361618   \n",
       "compound             1.0  0.610912  0.811086  0.740208            0.561191   \n",
       "dartboard1           1.0  1.000000  1.000000  0.008476           -0.002954   \n",
       "diamond9             1.0  0.875442  0.769478  0.151082            0.964994   \n",
       "smile1               1.0  1.000000  1.000000  0.332665            0.636015   \n",
       "\n",
       "             Agglomerative    KMeans  Random_k  Random_100  \n",
       "3-spiral         -0.003836 -0.005799       NaN         NaN  \n",
       "aggregation       0.701754  0.714612       NaN         NaN  \n",
       "chainlink        -0.001000  0.064090       NaN         NaN  \n",
       "complex8          0.511867  0.465176       NaN         NaN  \n",
       "complex9          0.327539  0.360767       NaN         NaN  \n",
       "compound          0.501062  0.527150       NaN         NaN  \n",
       "dartboard1        0.041462 -0.002991       NaN         NaN  \n",
       "diamond9          0.996266  0.961846       NaN         NaN  \n",
       "smile1            0.568858  0.545919       NaN         NaN  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.latex_pandas import gather_and_aggregate_data\n",
    "\n",
    "df_ari = gather_and_aggregate_data([\"results/ari/density_standardized/\"], [\"value\"], aggregation_funcs=[\"mean\"])\n",
    "df_ari = df_ari.drop([\"cluto-t4-8k\", \"cluto-t5-8k\", \"cluto-t7-10k\", \"cluto-t8-8k\"])\n",
    "df_ari.columns = df_ari.columns.get_level_values(0)\n",
    "df_ari.index = df_ari.index.get_level_values(0)\n",
    "df_ari = df_ari.reindex(columns=df_ari.columns.reindex(list(CLUSTER_ALGORITHMS.keys()))[0])\n",
    "df_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>DBSCAN</th>\n",
       "      <th>HDBSCAN</th>\n",
       "      <th>DPC</th>\n",
       "      <th>SpectralClustering</th>\n",
       "      <th>Agglomerative</th>\n",
       "      <th>KMeans</th>\n",
       "      <th>Random_k</th>\n",
       "      <th>Random_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3-spiral</th>\n",
       "      <td>0.587948</td>\n",
       "      <td>0.587948</td>\n",
       "      <td>0.489028</td>\n",
       "      <td>0.587948</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.305651</td>\n",
       "      <td>0.298020</td>\n",
       "      <td>0.669705</td>\n",
       "      <td>0.498282</td>\n",
       "      <td>0.277962</td>\n",
       "      <td>0.214675</td>\n",
       "      <td>0.187767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chainlink</th>\n",
       "      <td>0.835047</td>\n",
       "      <td>0.835047</td>\n",
       "      <td>0.835047</td>\n",
       "      <td>-0.012833</td>\n",
       "      <td>0.479781</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.077678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex8</th>\n",
       "      <td>0.389960</td>\n",
       "      <td>0.391872</td>\n",
       "      <td>0.365744</td>\n",
       "      <td>-0.098652</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.069898</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex9</th>\n",
       "      <td>0.357815</td>\n",
       "      <td>0.357788</td>\n",
       "      <td>0.640266</td>\n",
       "      <td>-0.200613</td>\n",
       "      <td>-0.005967</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>0.347585</td>\n",
       "      <td>0.321406</td>\n",
       "      <td>0.446946</td>\n",
       "      <td>0.591612</td>\n",
       "      <td>0.164638</td>\n",
       "      <td>0.102480</td>\n",
       "      <td>0.138581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dartboard1</th>\n",
       "      <td>0.874343</td>\n",
       "      <td>0.874343</td>\n",
       "      <td>0.874343</td>\n",
       "      <td>0.479126</td>\n",
       "      <td>-0.006421</td>\n",
       "      <td>-0.069412</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diamond9</th>\n",
       "      <td>0.217659</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>-0.081264</td>\n",
       "      <td>0.208820</td>\n",
       "      <td>0.217166</td>\n",
       "      <td>0.203520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile1</th>\n",
       "      <td>0.900074</td>\n",
       "      <td>0.900074</td>\n",
       "      <td>0.900074</td>\n",
       "      <td>0.525588</td>\n",
       "      <td>0.431486</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>0.335319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GroundTruth    DBSCAN   HDBSCAN       DPC  SpectralClustering  \\\n",
       "3-spiral        0.587948  0.587948  0.489028  0.587948           -0.002035   \n",
       "aggregation     0.305651  0.298020  0.669705  0.498282            0.277962   \n",
       "chainlink       0.835047  0.835047  0.835047 -0.012833            0.479781   \n",
       "complex8        0.389960  0.391872  0.365744 -0.098652            0.040382   \n",
       "complex9        0.357815  0.357788  0.640266 -0.200613           -0.005967   \n",
       "compound        0.347585  0.321406  0.446946  0.591612            0.164638   \n",
       "dartboard1      0.874343  0.874343  0.874343  0.479126           -0.006421   \n",
       "diamond9        0.217659  0.208595  0.166034 -0.081264            0.208820   \n",
       "smile1          0.900074  0.900074  0.900074  0.525588            0.431486   \n",
       "\n",
       "             Agglomerative    KMeans  Random_k  Random_100  \n",
       "3-spiral          0.002716 -0.001710       NaN         NaN  \n",
       "aggregation       0.214675  0.187767       NaN         NaN  \n",
       "chainlink         0.005968  0.077678       NaN         NaN  \n",
       "complex8          0.069898  0.037661       NaN         NaN  \n",
       "complex9          0.001961  0.046401       NaN         NaN  \n",
       "compound          0.102480  0.138581       NaN         NaN  \n",
       "dartboard1       -0.069412 -0.004718       NaN         NaN  \n",
       "diamond9          0.217166  0.203520       NaN         NaN  \n",
       "smile1            0.368517  0.335319       NaN         NaN  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disco = gather_and_aggregate_data([\"clustering_results2/density_standardized/\"], [\"value\"], aggregation_funcs=[\"mean\"])\n",
    "df_disco = df_disco.drop([\"cluto-t4-8k\", \"cluto-t5-8k\", \"cluto-t7-10k\", \"cluto-t8-8k\"])\n",
    "df_disco.columns = df_disco.columns.get_level_values(0)\n",
    "df_disco.index = df_disco.index.get_level_values(0)\n",
    "df_disco = df_disco.reindex(columns=df_disco.columns.reindex(list(CLUSTER_ALGORITHMS.keys()))[0])\n",
    "df_disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n",
      "[ nan 0.48 0.25 0.61 0.6  0.75 0.96 0.71]\n",
      "[ 1.   -0.13  0.98  0.89  0.35  0.6   0.92  0.95  0.88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3179926/3885098068.py:5: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  print(np.round(np.array(list(pearsonr(df1.to_numpy(), df2.to_numpy(), axis=0))[0]), 2))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "print(round(pearsonr(df_ari.to_numpy(), df_disco.to_numpy(), axis=None)[0],2))\n",
    "# 0.69\n",
    "\n",
    "print(np.round(np.array(list(pearsonr(df1.to_numpy(), df2.to_numpy(), axis=0))[0]), 2))\n",
    "# [ nan 0.48 0.25 0.61 0.6  0.75 0.96 0.71]\n",
    "\n",
    "print(np.round(np.array(list(pearsonr(df_ari.to_numpy(), df_disco.to_numpy(), axis=1))[0]), 2))\n",
    "# [ 1.   -0.13  0.98  0.89  0.35  0.6   0.92  0.95  0.88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-spiral: GroundTruth, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "aggregation: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "chainlink: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "cluto-t4-8k: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "cluto-t5-8k: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "cluto-t7-10k: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "cluto-t8-8k: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "complex8: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "complex9: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "compound: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "dartboard1: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "diamond9: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "smile1: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Synth_low: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Synth_high: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "HAR: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "letterrec.: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "htru2: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Mice: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Pendigits: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Weizmann: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Keck: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "COIL20: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "COIL100: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "cmu_faces: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "Optdigits: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "USPS: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "MNIST: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "FMNIST: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n",
      "KMNIST: GroundTruth, DBSCAN, HDBSCAN, DPC, SpectralClustering, Agglomerative, MeanShift, KMeans, Random_k, Random_100, \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "from os.path import exists\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    normalized_mutual_info_score as nmi,\n",
    "    adjusted_rand_score as ari,\n",
    ")\n",
    "\n",
    "CLUSTERINGS_PATH = \"/export/share/pascalw777dm/DISCO/clusterings/*/\"\n",
    "\n",
    "from datasets.density_datasets import Datasets as DensityDatasets\n",
    "from datasets.real_world_datasets import Datasets as RealWorldDatasets\n",
    "from src.utils.cluster_algorithms import CLUSTER_ALGORITHMS\n",
    "\n",
    "Datasets = [dataset for datasets in [DensityDatasets, RealWorldDatasets] for dataset in datasets]\n",
    "Clusterers = CLUSTER_ALGORITHMS.keys()\n",
    "\n",
    "def load_clustering(dataset, path, run):\n",
    "    X, l = dataset.standardized_data_cached\n",
    "\n",
    "    np.random.seed(0)\n",
    "    seeds = np.random.choice(10_000, size=run + 1, replace=False)\n",
    "    np.random.seed(seeds[-1])\n",
    "    shuffle_data_index = np.random.choice(len(X), size=len(X), replace=False)\n",
    "    l = l[shuffle_data_index]\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    l_ = df[\"value\"][0]\n",
    "    l_ = np.array(literal_eval(\",\".join(l_.split()).replace(\"[,\", \"[\")))\n",
    "\n",
    "    return l, l_\n",
    "\n",
    "\n",
    "data_ari = []\n",
    "\n",
    "for dataset in Datasets:\n",
    "    print(dataset.name + \": \", end=\"\")\n",
    "\n",
    "    for clusterer in Clusterers:\n",
    "        print(clusterer, end=\", \")\n",
    "        file_paths = glob.glob(CLUSTERINGS_PATH + f\"{dataset.id}/{clusterer}_*.csv\")\n",
    "\n",
    "        for path in file_paths:\n",
    "            run = re.search(r\".*_(\\d+).csv\", path)\n",
    "            if not run:\n",
    "                continue\n",
    "            run = int(run.group(1))\n",
    "\n",
    "            l, l_ = load_clustering(dataset, path, run)\n",
    "\n",
    "            n_clust = len(set(l_[l_ >= 0]))\n",
    "            ind = np.where(l_ == -1)[0]\n",
    "            for i in ind:\n",
    "                l_[i] = n_clust\n",
    "                n_clust += 1\n",
    "            try:\n",
    "                nmi_val = nmi(l, l_)\n",
    "                ari_val = ari(l, l_)\n",
    "            except:\n",
    "                print(f\"Error: {dataset.name=}, {clusterer=}, {path=}, {run=}\")\n",
    "\n",
    "            data_ari.append((dataset.id, clusterer, run, nmi_val, ari_val))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DPC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_algorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLUSTER_ALGORITHMS\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mCLUSTER_ALGORITHMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDPC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m CLUSTER_ALGORITHMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeanShift\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m CLUSTER_ALGORITHMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpectralClustering\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DPC'"
     ]
    }
   ],
   "source": [
    "from src.utils.cluster_algorithms import CLUSTER_ALGORITHMS\n",
    "\n",
    "del CLUSTER_ALGORITHMS[\"DPC\"]\n",
    "del CLUSTER_ALGORITHMS[\"MeanShift\"]\n",
    "del CLUSTER_ALGORITHMS[\"SpectralClustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterer</th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>DBSCAN</th>\n",
       "      <th>HDBSCAN</th>\n",
       "      <th>Agglomerative</th>\n",
       "      <th>KMeans</th>\n",
       "      <th>Random_k</th>\n",
       "      <th>Random_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">COIL20</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.773709</td>\n",
       "      <td>0.685521</td>\n",
       "      <td>0.551159</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.565794</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-0.001213</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586838</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572283</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">three_spiral</th>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888605</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>0.002578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.005877</td>\n",
       "      <td>-0.002031</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939044</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.006030</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>-0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.005877</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>-0.000952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "clusterer         GroundTruth    DBSCAN   HDBSCAN  Agglomerative    KMeans  \\\n",
       "dataset      run                                                             \n",
       "COIL20       0            1.0  0.653905  0.773709       0.685521  0.551159   \n",
       "             1            NaN       NaN       NaN            NaN  0.565794   \n",
       "             2            NaN       NaN       NaN            NaN  0.578947   \n",
       "             3            NaN       NaN       NaN            NaN  0.586838   \n",
       "             4            NaN       NaN       NaN            NaN  0.572283   \n",
       "...                       ...       ...       ...            ...       ...   \n",
       "three_spiral 5            1.0  1.000000  0.888605      -0.003836 -0.005681   \n",
       "             6            1.0  1.000000  0.985556      -0.003836 -0.005877   \n",
       "             7            1.0  1.000000  0.939044      -0.003836 -0.006030   \n",
       "             8            1.0  1.000000  0.985556      -0.003836 -0.005681   \n",
       "             9            1.0  1.000000  0.985556      -0.003836 -0.005877   \n",
       "\n",
       "clusterer         Random_k  Random_100  \n",
       "dataset      run                        \n",
       "COIL20       0    0.001243    0.001258  \n",
       "             1    0.000170         NaN  \n",
       "             2   -0.001213         NaN  \n",
       "             3   -0.002198         NaN  \n",
       "             4    0.001710         NaN  \n",
       "...                    ...         ...  \n",
       "three_spiral 5   -0.001306    0.002578  \n",
       "             6   -0.002031    0.000192  \n",
       "             7   -0.002940   -0.001445  \n",
       "             8   -0.000721    0.001145  \n",
       "             9    0.001803   -0.000952  \n",
       "\n",
       "[240 rows x 7 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_algorithms = list(CLUSTER_ALGORITHMS.keys())\n",
    "\n",
    "df_ari = pd.DataFrame(data_ari, columns=[\"dataset\", \"clusterer\", \"run\", \"nmi\", \"ari\"])\n",
    "# df.dataset = df.dataset.map(lambda x: id_to_name[x])\n",
    "df_ari = pd.pivot_table(df_ari, values=\"ari\", index=[\"dataset\", \"run\"], columns=[\"clusterer\"], dropna=False)\n",
    "df_ari = df_ari.reindex(columns=df_ari.columns.reindex(clustering_algorithms)[0])\n",
    "# df_ari = df_ari.reindex(index=pd.MultiIndex.from_product([df_ari.index.levels[0], df_ari.index]))\n",
    "df_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.latex_pandas import gather_and_aggregate_data\n",
    "\n",
    "# df_ari = gather_and_aggregate_data([\"results/ari/density_standardized/\"], [\"value\"], aggregation_funcs=[\"mean\"])\n",
    "# df_ari = df_ari.drop([\"cluto-t4-8k\", \"cluto-t5-8k\", \"cluto-t7-10k\", \"cluto-t8-8k\"])\n",
    "# df_ari.columns = df_ari.columns.get_level_values(0)\n",
    "# df_ari.index = df_ari.index.get_level_values(0)\n",
    "# df_ari = df_ari.reindex(columns=df_ari.columns.reindex(list(CLUSTER_ALGORITHMS.keys()))[0])\n",
    "# df_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "path = \"clusterings_metrics/*/\"\n",
    "\n",
    "def extract_dataset_clusterer_cvi(file_path):\n",
    "    file_path = file_path.split(\"/\")\n",
    "    dataset = file_path[-2]\n",
    "    [clusterer_run, cvi] = file_path[-1].split(\"##\")\n",
    "    clusterer_run = clusterer_run.split(\"_\")\n",
    "    clusterer = \"_\".join(clusterer_run[:-1])\n",
    "    run = clusterer_run[-1]\n",
    "    cvi = cvi.split(\".\")[0]\n",
    "    return (dataset, clusterer, cvi, int(run))\n",
    "\n",
    "data = [\n",
    "    extract_dataset_clusterer_cvi(file_path) + (float(np.loadtxt(file_path)),)\n",
    "    for file_path in glob.glob(f\"{path}*/*\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.density_datasets import Datasets as DensityDatasets\n",
    "\n",
    "clustering_algorithms = list(CLUSTER_ALGORITHMS.keys())\n",
    "# clustering_algorithms.remove(\"MeanShift\")  # contains nan values\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"dataset\", \"clusterer\", \"cvi\", \"run\", \"value\"])\n",
    "df_pivot = pd.pivot_table(df, values=\"value\", index=[\"cvi\", \"dataset\", \"run\"], columns=[\"clusterer\"], dropna=False)\n",
    "df_pivot = df_pivot.reindex(columns=df_pivot.columns.reindex(clustering_algorithms)[0])\n",
    "# df_pivot = df_pivot.reindex(index=pd.MultiIndex.from_product([df_pivot.index.levels[0], df_ari.index]))\n",
    "# df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COIL20', 'HAR', 'Mice', 'Optdigits', 'Pendigits', 'Synth_high',\n",
       "       'Synth_low', 'USPS', 'aggregation', 'chainlink', 'cluto_t4_8k',\n",
       "       'cluto_t5_8k', 'cluto_t7_10k', 'cluto_t8_8k', 'cmu_faces', 'complex8',\n",
       "       'complex9', 'compound', 'dartboard1', 'diamond9', 'htru2', 'letterrec',\n",
       "       'smile1', 'three_spiral'],\n",
       "      dtype='object', name='dataset')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.index.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CDBW', 'CVDD', 'CVNN', 'DBCV', 'DCSI', 'DISCO', 'LCCV', 'SILHOUETTE',\n",
       "       'S_DBW', 'VIASCKDE'],\n",
       "      dtype='object', name='cvi')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>clusterer</th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>DBSCAN</th>\n",
       "      <th>HDBSCAN</th>\n",
       "      <th>Agglomerative</th>\n",
       "      <th>KMeans</th>\n",
       "      <th>Random_k</th>\n",
       "      <th>Random_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cvi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">SILHOUETTE</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">htru2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.549011</td>\n",
       "      <td>0.451148</td>\n",
       "      <td>0.427159</td>\n",
       "      <td>0.579897</td>\n",
       "      <td>0.632623</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.104848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "clusterer               GroundTruth    DBSCAN   HDBSCAN  Agglomerative  \\\n",
       "cvi        dataset run                                                   \n",
       "SILHOUETTE htru2   0       0.549011  0.451148  0.427159       0.579897   \n",
       "                   1            NaN       NaN       NaN            NaN   \n",
       "                   2            NaN       NaN       NaN            NaN   \n",
       "                   3            NaN       NaN       NaN            NaN   \n",
       "                   4            NaN       NaN       NaN            NaN   \n",
       "                   5            NaN       NaN       NaN            NaN   \n",
       "                   6            NaN       NaN       NaN            NaN   \n",
       "                   7            NaN       NaN       NaN            NaN   \n",
       "                   8            NaN       NaN       NaN            NaN   \n",
       "                   9            NaN       NaN       NaN            NaN   \n",
       "\n",
       "clusterer                 KMeans  Random_k  Random_100  \n",
       "cvi        dataset run                                  \n",
       "SILHOUETTE htru2   0    0.632623 -0.000024   -0.104848  \n",
       "                   1         NaN       NaN         NaN  \n",
       "                   2         NaN       NaN         NaN  \n",
       "                   3         NaN       NaN         NaN  \n",
       "                   4         NaN       NaN         NaN  \n",
       "                   5         NaN       NaN         NaN  \n",
       "                   6         NaN       NaN         NaN  \n",
       "                   7         NaN       NaN         NaN  \n",
       "                   8         NaN       NaN         NaN  \n",
       "                   9         NaN       NaN         NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.loc[(df_pivot.index.get_level_values(0) == \"SILHOUETTE\") & (df_pivot.index.get_level_values(1) == \"htru2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_pearsonr_without_nans_row(ari_row, cvi_row):\n",
    "    ari_nans = np.isnan(ari_row)\n",
    "    ari_row = ari_row[~ari_nans]\n",
    "    cvi_row = cvi_row[~ari_nans]\n",
    "    n_ari = len(ari_row)\n",
    "    cvi_nans = np.isnan(cvi_row)\n",
    "    n_cvi = len(cvi_row[~cvi_nans])\n",
    "    # print(n_ari, n_cvi, ari_row, cvi_row)\n",
    "\n",
    "    pearson_value = np.nan\n",
    "    pearson_scaled = np.nan\n",
    "    if n_cvi >= 2:\n",
    "        pearson_value = pearsonr(ari_row[~cvi_nans], cvi_row[~cvi_nans])[0]\n",
    "        pearson_scaled = (n_cvi / n_ari) * pearson_value\n",
    "\n",
    "    if np.isnan(pearson_value):\n",
    "        return np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        return (pearson_scaled, pearson_value, n_cvi / n_ari)\n",
    "\n",
    "\n",
    "def get_pearsonr_without_nans_rowwise(ari_matrix, cvi_matrix):\n",
    "    return [get_pearsonr_without_nans_row(ari_row, cvi_row) for (ari_row, cvi_row) in zip(ari_matrix, cvi_matrix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3749285/3870211130.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value = pearsonr(ari_row[~cvi_nans], cvi_row[~cvi_nans])[0]\n"
     ]
    }
   ],
   "source": [
    "CVIs = set(df_pivot.index.get_level_values(0))\n",
    "df_ari = df_ari.reindex(columns=df_ari.columns.reindex(clustering_algorithms)[0])\n",
    "np_ari_matrix = df_ari.to_numpy()\n",
    "\n",
    "pearson_values = []\n",
    "for cvi in CVIs:\n",
    "    df_cvi = df_pivot.xs(cvi)\n",
    "    np_cvi_matrix = df_cvi.to_numpy()\n",
    "    pearson_per_dataset = get_pearsonr_without_nans_rowwise(np_ari_matrix, np_cvi_matrix)\n",
    "    pearson_values += [\n",
    "        (cvi,) + x\n",
    "        for x in map(lambda x: (x[0][0], x[0][1], x[1][0], x[1][1], x[1][2]), zip(df_cvi.index, pearson_per_dataset))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pearson[(df_pearson.cvi == \"DISCO\") & (df_pearson.dataset == \"compound\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import SELECTED_METRICS\n",
    "\n",
    "dataset_names = {dataset.id: dataset.name for dataset in Datasets}\n",
    "for dataset in [\"cluto_t5_8k\", \"HAR\", \"letterrec\", \"USPS\", \"Mice\"]:\n",
    "    del dataset_names[dataset]\n",
    "\n",
    "\n",
    "def reorder_rows(df_reorder, first_column, second_column, dataset_dict):\n",
    "    df_reorder[second_column] = second_column\n",
    "    df_reorder = df_reorder.reset_index().set_index([first_column, second_column])\n",
    "    df_reorder = df_reorder.reindex(index=dataset_dict, level=0)\n",
    "    df_reorder = df_reorder.rename(index=dataset_dict, level=0)\n",
    "    return df_reorder\n",
    "\n",
    "\n",
    "def create_pearson_pivot(pearson_values, values=\"pearson_true\", name=\"pearson\", second_column=\"mean\"):\n",
    "    df_pearson = pd.DataFrame(\n",
    "        pearson_values, columns=[\"cvi\", \"dataset\", \"run\", \"pearson_scaled\", \"pearson_true\", \"percent_nans\"]\n",
    "    )\n",
    "    df_pearson_pivot = pd.pivot_table(df_pearson, values=values, index=[\"dataset\"], columns=[\"cvi\"])\n",
    "    df_pearson_pivot = df_pearson_pivot.reindex(columns=df_pearson_pivot.columns.reindex(SELECTED_METRICS)[0])\n",
    "    df_pearson_pivot.columns = pd.MultiIndex.from_tuples(\n",
    "        [(x, name) for x in df_pearson_pivot.columns.reindex(SELECTED_METRICS)[0]]\n",
    "    )\n",
    "    df_pearson_pivot = reorder_rows(df_pearson_pivot, \"dataset\", second_column, dataset_names)\n",
    "    return df_pearson_pivot\n",
    "\n",
    "df_pearson_pivot = create_pearson_pivot(pearson_values)\n",
    "df_nans = create_pearson_pivot(pearson_values, values=\"percent_nans\", second_column=\"std\")\n",
    "\n",
    "df_pearson_merged = pd.concat((df_pearson_pivot, df_nans))\n",
    "df_pearson_merged = df_pearson_merged.reindex(index=dataset_names.values(), level=0)\n",
    "# df_pearson_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>DISCO</th>\n",
       "      <th>DBCV</th>\n",
       "      <th>DCSI</th>\n",
       "      <th>LCCV</th>\n",
       "      <th>VIASCKDE</th>\n",
       "      <th>CVDD</th>\n",
       "      <th>CDBW</th>\n",
       "      <th>CVNN</th>\n",
       "      <th>SILHOUETTE</th>\n",
       "      <th>S_DBW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pearson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3-spiral</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.891599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.316021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024322</td>\n",
       "      <td>0.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggregation</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.809514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.864769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899516</td>\n",
       "      <td>-0.811281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">chainlink</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.927754</td>\n",
       "      <td>0.997091</td>\n",
       "      <td>0.722714</td>\n",
       "      <td>0.900733</td>\n",
       "      <td>0.518371</td>\n",
       "      <td>0.996722</td>\n",
       "      <td>0.769252</td>\n",
       "      <td>-0.365282</td>\n",
       "      <td>0.269905</td>\n",
       "      <td>0.265033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cluto-t4-8k</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.444260</td>\n",
       "      <td>0.775642</td>\n",
       "      <td>0.938152</td>\n",
       "      <td>0.761248</td>\n",
       "      <td>0.570231</td>\n",
       "      <td>0.183738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.426928</td>\n",
       "      <td>0.424031</td>\n",
       "      <td>-0.538439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cluto-t7-10k</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.486584</td>\n",
       "      <td>0.838712</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>0.324223</td>\n",
       "      <td>0.503785</td>\n",
       "      <td>-0.014723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.394239</td>\n",
       "      <td>0.134944</td>\n",
       "      <td>-0.531855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cluto-t8-8k</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.913478</td>\n",
       "      <td>0.714112</td>\n",
       "      <td>0.885313</td>\n",
       "      <td>0.596372</td>\n",
       "      <td>0.819413</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.585137</td>\n",
       "      <td>0.084428</td>\n",
       "      <td>-0.681041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">complex8</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.957091</td>\n",
       "      <td>0.905265</td>\n",
       "      <td>0.900860</td>\n",
       "      <td>0.901658</td>\n",
       "      <td>0.871469</td>\n",
       "      <td>0.476042</td>\n",
       "      <td>0.484285</td>\n",
       "      <td>-0.594906</td>\n",
       "      <td>0.307959</td>\n",
       "      <td>-0.715942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">complex9</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.563507</td>\n",
       "      <td>0.596278</td>\n",
       "      <td>0.782806</td>\n",
       "      <td>0.751566</td>\n",
       "      <td>0.685843</td>\n",
       "      <td>0.192457</td>\n",
       "      <td>0.661307</td>\n",
       "      <td>-0.468062</td>\n",
       "      <td>-0.015197</td>\n",
       "      <td>-0.629568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">compound</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.860771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.621157</td>\n",
       "      <td>-0.675973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dartboard1</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.968281</td>\n",
       "      <td>0.997854</td>\n",
       "      <td>0.988326</td>\n",
       "      <td>0.891118</td>\n",
       "      <td>0.643520</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>-0.533900</td>\n",
       "      <td>-0.350972</td>\n",
       "      <td>-0.200700</td>\n",
       "      <td>-0.362205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">diamond9</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.989852</td>\n",
       "      <td>0.871263</td>\n",
       "      <td>0.993102</td>\n",
       "      <td>0.935235</td>\n",
       "      <td>0.989891</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.137134</td>\n",
       "      <td>-0.684512</td>\n",
       "      <td>0.968364</td>\n",
       "      <td>-0.873273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">smile1</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.965984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964024</td>\n",
       "      <td>0.946223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791980</td>\n",
       "      <td>-0.935836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Synth_low</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.981269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924764</td>\n",
       "      <td>0.791077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876959</td>\n",
       "      <td>-0.858785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Synth_high</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.968688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955192</td>\n",
       "      <td>0.727194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889262</td>\n",
       "      <td>-0.874013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">htru2</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.374021</td>\n",
       "      <td>-0.419376</td>\n",
       "      <td>-0.267405</td>\n",
       "      <td>0.557996</td>\n",
       "      <td>0.504971</td>\n",
       "      <td>0.584333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.379809</td>\n",
       "      <td>0.734581</td>\n",
       "      <td>-0.240544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Pendigits</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.403059</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.562303</td>\n",
       "      <td>0.790346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505199</td>\n",
       "      <td>0.104069</td>\n",
       "      <td>-0.439198</td>\n",
       "      <td>0.782158</td>\n",
       "      <td>-0.487588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">COIL20</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.957938</td>\n",
       "      <td>0.934410</td>\n",
       "      <td>0.941705</td>\n",
       "      <td>0.931268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639869</td>\n",
       "      <td>0.218434</td>\n",
       "      <td>-0.658366</td>\n",
       "      <td>0.851512</td>\n",
       "      <td>-0.902898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cmu_faces</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.620793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714315</td>\n",
       "      <td>0.783311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807456</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>-0.536016</td>\n",
       "      <td>0.804602</td>\n",
       "      <td>-0.558468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Optdigits</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.910725</td>\n",
       "      <td>0.505726</td>\n",
       "      <td>0.833229</td>\n",
       "      <td>0.901444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656953</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>-0.615900</td>\n",
       "      <td>0.869409</td>\n",
       "      <td>-0.706745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DISCO      DBCV      DCSI      LCCV  VIASCKDE      CVDD  \\\n",
       "                    pearson   pearson   pearson   pearson   pearson   pearson   \n",
       "dataset                                                                         \n",
       "3-spiral     mean  0.891599       NaN       NaN  0.858211       NaN       NaN   \n",
       "             std   1.000000  0.857143  0.857143  1.000000  0.857143  0.857143   \n",
       "aggregation  mean  0.809514       NaN       NaN  0.924109       NaN       NaN   \n",
       "             std   1.000000  0.971429  0.985714  1.000000  0.971429  0.971429   \n",
       "chainlink    mean  0.927754  0.997091  0.722714  0.900733  0.518371  0.996722   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "cluto-t4-8k  mean  0.444260  0.775642  0.938152  0.761248  0.570231  0.183738   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "cluto-t7-10k mean  0.486584  0.838712  0.888640  0.324223  0.503785 -0.014723   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "cluto-t8-8k  mean  0.913478  0.714112  0.885313  0.596372  0.819413 -0.015323   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "complex8     mean  0.957091  0.905265  0.900860  0.901658  0.871469  0.476042   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "complex9     mean  0.563507  0.596278  0.782806  0.751566  0.685843  0.192457   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "compound     mean  0.860771       NaN       NaN  0.929154       NaN       NaN   \n",
       "             std   1.000000  0.728571  0.885714  1.000000  0.728571  0.728571   \n",
       "dartboard1   mean  0.968281  0.997854  0.988326  0.891118  0.643520  0.999483   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "diamond9     mean  0.989852  0.871263  0.993102  0.935235  0.989891  0.672043   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "smile1       mean  0.965984       NaN  0.964024  0.946223       NaN       NaN   \n",
       "             std   1.000000  0.971429  1.000000  1.000000  0.971429  0.971429   \n",
       "Synth_low    mean  0.981269       NaN  0.924764  0.791077       NaN       NaN   \n",
       "             std   1.000000  0.857143  1.000000  1.000000  0.857143  0.857143   \n",
       "Synth_high   mean  0.968688       NaN  0.955192  0.727194       NaN       NaN   \n",
       "             std   1.000000  0.857143  1.000000  1.000000  0.857143  0.857143   \n",
       "htru2        mean  0.374021 -0.419376 -0.267405  0.557996  0.504971  0.584333   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "Pendigits    mean  0.403059  0.106440  0.562303  0.790346       NaN  0.505199   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  0.857143  1.000000   \n",
       "COIL20       mean  0.957938  0.934410  0.941705  0.931268       NaN  0.639869   \n",
       "             std   1.000000  1.000000  1.000000  1.000000       NaN  1.000000   \n",
       "cmu_faces    mean  0.620793       NaN  0.714315  0.783311       NaN  0.807456   \n",
       "             std   1.000000  0.285714  1.000000  1.000000       NaN  1.000000   \n",
       "Optdigits    mean  0.910725  0.505726  0.833229  0.901444       NaN  0.656953   \n",
       "             std   1.000000  1.000000  1.000000  1.000000  0.857143  1.000000   \n",
       "\n",
       "                       CDBW      CVNN SILHOUETTE     S_DBW  \n",
       "                    pearson   pearson    pearson   pearson  \n",
       "dataset                                                     \n",
       "3-spiral     mean  0.316021       NaN  -0.024322  0.423800  \n",
       "             std   1.000000  0.857143   1.000000  1.000000  \n",
       "aggregation  mean  0.864769       NaN   0.899516 -0.811281  \n",
       "             std   1.000000  0.971429   1.000000  1.000000  \n",
       "chainlink    mean  0.769252 -0.365282   0.269905  0.265033  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "cluto-t4-8k  mean       NaN -0.426928   0.424031 -0.538439  \n",
       "             std   0.857143  1.000000   1.000000  1.000000  \n",
       "cluto-t7-10k mean       NaN -0.394239   0.134944 -0.531855  \n",
       "             std   0.857143  1.000000   1.000000  1.000000  \n",
       "cluto-t8-8k  mean       NaN -0.585137   0.084428 -0.681041  \n",
       "             std   0.857143  1.000000   1.000000  1.000000  \n",
       "complex8     mean  0.484285 -0.594906   0.307959 -0.715942  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "complex9     mean  0.661307 -0.468062  -0.015197 -0.629568  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "compound     mean  0.675855       NaN   0.621157 -0.675973  \n",
       "             std   1.000000  0.728571   1.000000  1.000000  \n",
       "dartboard1   mean -0.533900 -0.350972  -0.200700 -0.362205  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "diamond9     mean  0.137134 -0.684512   0.968364 -0.873273  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "smile1       mean  0.685327       NaN   0.791980 -0.935836  \n",
       "             std   1.000000  0.971429   1.000000  1.000000  \n",
       "Synth_low    mean  0.138926       NaN   0.876959 -0.858785  \n",
       "             std   1.000000  0.857143   1.000000  1.000000  \n",
       "Synth_high   mean  0.564436       NaN   0.889262 -0.874013  \n",
       "             std   1.000000  0.857143   1.000000  1.000000  \n",
       "htru2        mean       NaN -0.379809   0.734581 -0.240544  \n",
       "             std   0.857143  1.000000   1.000000  1.000000  \n",
       "Pendigits    mean  0.104069 -0.439198   0.782158 -0.487588  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "COIL20       mean  0.218434 -0.658366   0.851512 -0.902898  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "cmu_faces    mean -0.028423 -0.536016   0.804602 -0.558468  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  \n",
       "Optdigits    mean  0.124432 -0.615900   0.869409 -0.706745  \n",
       "             std   1.000000  1.000000   1.000000  1.000000  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_one_mask = df_pearson_merged.loc[df_pearson_merged.index.get_level_values(1) == 'std'] < 1.0\n",
    "not_one_mask.index = pd.MultiIndex.from_tuples(\n",
    "    [(dataset, 'mean') for dataset, _std in not_one_mask.index],\n",
    "    names=not_one_mask.index.names\n",
    ")\n",
    "df_pearson_merged[not_one_mask] = np.nan\n",
    "df_pearson_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustpy.utils.evaluation import evaluation_df_to_latex_table\n",
    "from src.utils.latex_pandas import latex_coloring, regex_file, run_regex\n",
    "from src.utils.metrics import METRIC_ABBREV_PLAIN, METRIC_ABBREV_TABLES\n",
    "\n",
    "latex_pearson = \"latex/pearson.tex\"\n",
    "\n",
    "evaluation_df_to_latex_table(\n",
    "    df_pearson_merged,\n",
    "    latex_pearson,\n",
    "    best_in_bold=False,\n",
    "    second_best_underlined=False,\n",
    "    in_percent=True,\n",
    "    decimal_places=2,\n",
    "    use_std=False,\n",
    ")\n",
    "\n",
    "latex_coloring(latex_pearson, skiprows=6, axis=None, min_value=-100, max_value=100, lower_is_better=[\"CVNN\", \"S_DBW\"], inverse_color=[\"CVNN\", \"S_DBW\"])\n",
    "regex_file(\n",
    "    latex_pearson,\n",
    "    \"\",\n",
    "    metric_abbrev=METRIC_ABBREV_TABLES,\n",
    "    # categories=[(\"3-spiral\", 14, \"Density-based Benchmark Data\"), (\"COIL20\", 5, \"Real World\")],\n",
    "    # categories=[(\"three_spiral\", 13, \"Density-based 2D-Data\"), (\"Synth_low\", 7, \"Tabular Data\"), (\"COIL20\", 4, \"Images\")],\n",
    ")\n",
    "run_regex(\n",
    "    [\n",
    "        r\"s/\\$\\s*nan\\s*\\$/-/g\",\n",
    "        # r\"s/- /- & \\$(0)\\$ /g\",\n",
    "        # r\"s/\\\\pm\\s*(\\d+).00?(\\}?)\\$/$2\\$ & \\$($1)\\$/g\",\n",
    "        # r\"s/(\\\\cellcolor\\{.*?\\})(.*?)&/$1$2& $1/g\",\n",
    "    ],\n",
    "    latex_pearson,\n",
    ")\n",
    "\n",
    "# \\\\pm\\s*(\\d+).00?(\\}?)\\$   /   $2$ & $($1)$\n",
    "# (\\\\cellcolor\\{.*?\\})(.*?)&   /   $1$2& $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disco = df_pivot.xs(\"DISCO\")\n",
    "df_help = df_ari.mean(axis=1)\n",
    "df_help[df_help.index.get_level_values(0)[2]]\n",
    "\n",
    "df_disco2 = pd.DataFrame()\n",
    "for i in df_help.index.get_level_values(0):\n",
    "    df_disco2[i] = df_disco.loc[(i, df_help[i].idxmax())]\n",
    "df_disco2 = df_disco2.T\n",
    "df_disco2.columns = pd.MultiIndex.from_tuples([(x, \"clusterer\") for x in df_disco2.columns])\n",
    "df_disco2.index.names = [\"dataset\"]\n",
    "df_disco2 = reorder_rows(df_disco2, \"dataset\", \"mean\", dataset_names)\n",
    "\n",
    "df_ari2 = pd.DataFrame()\n",
    "for i in df_help.index.get_level_values(0):\n",
    "    df_ari2[i] = df_ari.loc[(i, df_help[i].idxmax())]\n",
    "df_ari2 = df_ari2.T\n",
    "df_ari2.columns = pd.MultiIndex.from_tuples([(x, \"clusterer\") for x in df_ari2.columns])\n",
    "df_ari2.index.names = [\"dataset\"]\n",
    "df_ari2 = reorder_rows(df_ari2, \"dataset\", \"mean\", dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustpy.utils.evaluation import evaluation_df_to_latex_table\n",
    "from src.utils.latex_pandas import latex_coloring, regex_file, run_regex\n",
    "from src.utils.metrics import METRIC_ABBREV_PLAIN\n",
    "\n",
    "latex_pearson = \"latex/df_disco2.tex\"\n",
    "\n",
    "evaluation_df_to_latex_table(\n",
    "    df_disco2,\n",
    "    latex_pearson,\n",
    "    best_in_bold=False,\n",
    "    second_best_underlined=False,\n",
    "    in_percent=True,\n",
    "    decimal_places=2,\n",
    ")\n",
    "\n",
    "latex_coloring(latex_pearson, skiprows=6, axis=None, min_value=-1, max_value=1)\n",
    "regex_file(\n",
    "    latex_pearson,\n",
    "    \"\",\n",
    "    metric_abbrev=METRIC_ABBREV_PLAIN,\n",
    "    categories=[(\"3-spiral\", 14, \"Density-based Benchmark Data\")],\n",
    "    # categories=[(\"three_spiral\", 13, \"Density-based 2D-Data\"), (\"Synth_low\", 7, \"Tabular Data\"), (\"COIL20\", 4, \"Images\")],\n",
    ")\n",
    "\n",
    "\n",
    "latex_pearson = \"latex/df_ari2.tex\"\n",
    "\n",
    "evaluation_df_to_latex_table(\n",
    "    df_ari2,\n",
    "    latex_pearson,\n",
    "    best_in_bold=False,\n",
    "    second_best_underlined=False,\n",
    "    in_percent=True,\n",
    "    decimal_places=2,\n",
    ")\n",
    "\n",
    "latex_coloring(latex_pearson, skiprows=6, axis=None, min_value=-1, max_value=1)\n",
    "regex_file(\n",
    "    latex_pearson,\n",
    "    \"\",\n",
    "    metric_abbrev=METRIC_ABBREV_PLAIN,\n",
    "    categories=[(\"3-spiral\", 14, \"Density-based Benchmark Data\")],\n",
    "    # categories=[(\"three_spiral\", 13, \"Density-based 2D-Data\"), (\"Synth_low\", 7, \"Tabular Data\"), (\"COIL20\", 4, \"Images\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 55, 65, 33, 33, 49, 64, 54, 59, 62, 68, 64, 64, 43, 29, 34, 66,\n",
       "       12, 56])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.round(100 * np.array(list(pearsonr(df_ari2.to_numpy(), df_disco2.to_numpy(), axis=1))[0]), 2)\n",
    "np.round(p_values / 100 * 65 + 5, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DISCO_ROOT_PATH = \"/export/share/pascalw777dm/DISCO\"\n",
    "sys.path.append(DISCO_ROOT_PATH)\n",
    "os.environ[\"TZ\"] = \"Europe/Vienna\"\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from src.utils.metrics import METRICS\n",
    "from datasets.density_datasets import Datasets as DensityDatasets\n",
    "from datasets.real_world_datasets import Datasets as RealWorldDatasets\n",
    "\n",
    "from src.utils.cluster_algorithms import CLUSTER_ALGORITHMS\n",
    "\n",
    "\n",
    "n_jobs = 50\n",
    "task_timeout = 12 * 60 * 60  # 12 hours\n",
    "\n",
    "# DATASETs = DensityDatasets\n",
    "# DATASET_PATH = \"density_standardized\"\n",
    "# RUNS = 10\n",
    "\n",
    "DATASETs = RealWorldDatasets.get_experiments_list()\n",
    "DATASET_PATH = \"real_world_standardized\"\n",
    "RUNS = 1\n",
    "\n",
    "for dataset in DATASETs:\n",
    "    for clusterer in CLUSTER_ALGORITHMS.keys():\n",
    "        for run in range(RUNS):\n",
    "            for metric_name, metric_func in METRICS.items():\n",
    "                metric_save_path = f\"{DISCO_ROOT_PATH}/clusterings_metrics/{DATASET_PATH}/{dataset.id}/{clusterer}_{run}##{metric_name}.csv\"\n",
    "                if os.path.exists(metric_save_path):\n",
    "                    value = np.loadtxt(metric_save_path)\n",
    "                    if np.isnan(value):\n",
    "                        pass\n",
    "                        # print(f\"{dataset.id}/{clusterer}_{run}##{metric_name}\")\n",
    "                        # os.remove(metric_save_path)\n",
    "                elif not os.path.exists(f\"{DISCO_ROOT_PATH}/clusterings/{DATASET_PATH}/{dataset.id}/{clusterer}_{run}.csv\"):\n",
    "                    pass\n",
    "                    # print(f\"Clustering not found -- {dataset.name=}, {clusterer=}, {run=}, {metric_name=}\")\n",
    "                else:\n",
    "                    pass\n",
    "                    print(f\"{dataset.id}/{clusterer}_{run}##{metric_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_path = f\"{DISCO_ROOT_PATH}/clusterings/density_standardized/three_spiral/MeanShift_0.csv\"\n",
    "os.path.exists(clustering_path)\n",
    "\n",
    "df = pd.read_csv(clustering_path)\n",
    "clustering_labels = df[\"value\"][0]\n",
    "clustering_labels = np.array(literal_eval(\",\".join(clustering_labels.split()).replace(\"[,\", \"[\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clustpy.utils.plots import plot_with_transformation\n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ari\n",
    "\n",
    "X, l = DensityDatasets.three_spiral.standardized_data_cached\n",
    "\n",
    "ari(l, clustering_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cvi_path = f\"{DISCO_ROOT_PATH}/clusterings_metrics/{DATASET_PATH}/letterrec/MeanShift_0##SILHOUETTE.csv\"\n",
    "os.path.exists(sample_cvi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
