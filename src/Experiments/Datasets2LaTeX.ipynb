{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:10:30.588168Z",
     "start_time": "2024-07-03T14:10:29.446448Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%store -r DISCO_ROOT_FOLDER\n",
    "if \"DISCO_ROOT_FOLDER\" in globals():\n",
    "    os.chdir(DISCO_ROOT_FOLDER)\n",
    "    sys.path.append(DISCO_ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections.abc import Mapping\n",
    "\n",
    "\n",
    "def deep_update(dict, dict_update):\n",
    "    for k, v in dict_update.items():\n",
    "        if isinstance(v, Mapping):\n",
    "            dict[k] = deep_update(dict.get(k, {}), v)\n",
    "        else:\n",
    "            dict[k] = v\n",
    "    return dict\n",
    "\n",
    "\n",
    "def group_by_column_and_aggregate_values(df, column, aggregation_func):\n",
    "    column_values = df.groupby([\"dataset\", \"measure\"])[column]\n",
    "    aggregated_values = getattr(column_values, aggregation_func)()\n",
    "\n",
    "    data_dict = defaultdict(dict)\n",
    "    for (dataset, eval_method), aggregated_value in aggregated_values.to_dict().items():\n",
    "        data_dict[(dataset, aggregation_func)][(eval_method, column)] = aggregated_value\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def calc_pairwise_column_aggregation_func_dict(df, columns, aggregation_funcs):\n",
    "    pairwise_column_aggregation_func = itertools.product(columns, aggregation_funcs)\n",
    "    pairwise_column_aggregation_func_data_dict = {}\n",
    "    for column, aggregations_func in pairwise_column_aggregation_func:\n",
    "        column_aggregation_func_data_dict = group_by_column_and_aggregate_values(\n",
    "            df, column, aggregations_func\n",
    "        )\n",
    "        deep_update(pairwise_column_aggregation_func_data_dict, column_aggregation_func_data_dict)\n",
    "    return pairwise_column_aggregation_func_data_dict\n",
    "\n",
    "\n",
    "def gather_and_aggregate_data(path, columns, aggregation_funcs):\n",
    "    dataframes = [pd.read_csv(path) for path in glob.glob(f\"{path}*/*\")]\n",
    "    df = pd.concat(dataframes)\n",
    "\n",
    "    data_dict = calc_pairwise_column_aggregation_func_dict(df, columns, aggregation_funcs)\n",
    "    return pd.DataFrame.from_dict(data_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_df(df, row_index, column_index, precision=3):\n",
    "    df = df.reindex(row_index)\n",
    "    df = df.reindex(columns=df.columns.reindex(column_index)[0])\n",
    "    df = df.round(precision)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_indices_and_reindex(df, dataset_names, aggregation_funcs, metrics, selection, precision=3):\n",
    "    row_index = list(itertools.product(dataset_names, aggregation_funcs))\n",
    "    column_index = list(itertools.product(metrics, selection))\n",
    "    return reindex_df(df, row_index=row_index, column_index=column_index, precision=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regex(expr_list, path):\n",
    "    for expr in expr_list:\n",
    "        expr = '\\'' + expr + '\\''\n",
    "        !perl -pwi -e {expr} {path}\n",
    "\n",
    "def regex_file(path, caption, categories=[]):\n",
    "    generell_stuff_regex = [\n",
    "        r's/table/table\\*/g',\n",
    "        r's/_/\\\\_/g',\n",
    "        r'1 while s/\\$nan \\\\pm nan\\$/-/g',\n",
    "        # Two digits\n",
    "        r's/(\\d\\.\\d) /${{1}}0 /g',\n",
    "        # arraystretch\n",
    "        r's/(\\\\begin\\{table\\*\\})/\\\\renewcommand\\{\\\\arraystretch\\}\\{1.2\\}\\n\\n\\n$1/g',\n",
    "        r's/(\\\\end\\{table\\*\\}.*$)/$1\\n\\n\\\\renewcommand\\{\\\\arraystretch\\}\\{1\\}\\n/g',\n",
    "    ]\n",
    "\n",
    "    remove_second_row_index_regex = [\n",
    "        # Remove second level of row index\n",
    "        r's/^(.*?& ).*?& /$1/g',\n",
    "        r's/(\\{tabular\\}\\{l\\|)l\\|/$1/g',\n",
    "        # Remove all midrules\n",
    "        r's/\\\\midrule\\n//g',\n",
    "        # Insert midrule after headline\n",
    "        # r's/(^\\\\textbf\\{Dataset\\}.*?$)/$1\\n\\\\midrule/g', \n",
    "    ]\n",
    "\n",
    "    caption_regex = [\n",
    "        # Caption\n",
    "        r's/\\\\caption\\{TODO\\}/\\\\caption\\{%s\\}/g'%(caption),\n",
    "    ]\n",
    "\n",
    "    categories_regex = [\n",
    "        # Generell categories stuff\n",
    "        r's/(\\{tabular\\}\\{)/$1r/g',\n",
    "        r's/^(.*?& )/& $1/g',\n",
    "    ] + [\n",
    "        # Categories\n",
    "        r\"s/(^& %s)/\\\\midrule\\n\\\\parbox[t]\\{2mm\\}\\{\\\\multirow\\{%s\\}\\{*\\}\\{\\\\rotatebox[origin=c]\\{90\\}\\{%s\\}\\}\\}\\n$1/g\"\n",
    "        % (first_dataset_in_category, nr_of_datasets_in_category, category_name)\n",
    "        for first_dataset_in_category, nr_of_datasets_in_category, category_name in categories\n",
    "    ]\n",
    "\n",
    "    run_regex(generell_stuff_regex, path)\n",
    "    run_regex(remove_second_row_index_regex, path)\n",
    "    run_regex(caption_regex, path)\n",
    "    if len(categories) > 0:\n",
    "        run_regex(categories_regex, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustpy.utils import evaluation_df_to_latex_table\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "    \"DISCO\",\n",
    "    \"DC_DUNN\",\n",
    "    ### Competitors\n",
    "    \"DBCV\",\n",
    "    \"DCSI\",\n",
    "    \"S_DBW\",\n",
    "    \"CDBW\",\n",
    "    \"CVDD\",\n",
    "    \"CVNN\",\n",
    "    \"DSI\",\n",
    "    ### Gauss\n",
    "    \"SILHOUETTE\",\n",
    "    \"DUNN\",\n",
    "    \"DB\",\n",
    "    \"CH\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_latex_file(\n",
    "    path,\n",
    "    latex_path,\n",
    "    dataset_names,\n",
    "    aggregation_funcs=[\"mean\", \"std\"],\n",
    "    metrics=METRICS,\n",
    "    selection=[\"value\", \"time\", \"process_time\"],\n",
    "    caption=\"TODO\",\n",
    "    categories=[],\n",
    "    precision=3,\n",
    "):\n",
    "    df_list = gather_and_aggregate_data(\n",
    "        path, columns=selection, aggregation_funcs=aggregation_funcs\n",
    "    )\n",
    "    df_matrix = calc_indices_and_reindex(\n",
    "        df_list, dataset_names, aggregation_funcs, metrics, selection, precision=precision\n",
    "    )\n",
    "    evaluation_df_to_latex_table(\n",
    "        df_matrix,\n",
    "        latex_path,\n",
    "        best_in_bold=False,\n",
    "        second_best_underlined=False,\n",
    "        in_percent=False,\n",
    "        decimal_places=2,\n",
    "    )\n",
    "    regex_file(latex_path, caption=caption, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.real_world_datasets import Datasets as RealWorldDatasets\n",
    "\n",
    "configs = {\n",
    "    \"real_world\": {\n",
    "        \"path\": \"results/real_world/\",\n",
    "        \"latex_path\": \"latex/real_world_experiments.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on real-world datasets.\",\n",
    "        \"categories\": [\n",
    "            (\"Synth\\\\_low\", 8, \"Tabular data\"),\n",
    "            (\"Weizmann\", 2, \"Video\"),\n",
    "            (\"COIL20\", 3, \"Image\"),\n",
    "            (\"Optdigits\", 5, \"MNIST\"),\n",
    "        ],\n",
    "    },\n",
    "    \"real_world_standardized\": {\n",
    "        \"path\": \"results/real_world_standardized/\",\n",
    "        \"latex_path\": \"latex/real_world_experiments_standardized.tex\",\n",
    "        \"dataset_names\": [dataset.name for dataset in RealWorldDatasets],\n",
    "        \"aggregation_funcs\": [\"mean\"],\n",
    "        \"metrics\": METRICS,\n",
    "        \"selection\": [\"value\"],\n",
    "        \"caption\": \"Evaluating on real-world datasets (standardized).\",\n",
    "        \"categories\": [\n",
    "            (\"Synth\\\\_low\", 8, \"Tabular data\"),\n",
    "            (\"Weizmann\", 2, \"Video\"),\n",
    "            (\"COIL20\", 3, \"Image\"),\n",
    "            (\"Optdigits\", 5, \"MNIST\"),\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpire.pool import WorkerPool\n",
    "\n",
    "pool = WorkerPool(n_jobs=30, use_dill=True)\n",
    "pool.map_unordered(generate_latex_file, configs.values())\n",
    "pool.stop_and_join()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
